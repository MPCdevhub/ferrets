{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker as sage\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = \"ferretData.csv\"\n",
    "\n",
    "# comma delimited is the default\n",
    "df = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "#one-hot encode the some columns\n",
    "df = pd.get_dummies(df, columns=['foodSituation','groomingSituation','livingSituation','disposition'])\n",
    "\n",
    "#remove the ferretID as it's not relevent for us.  We can remove the disposition_nice as the disposition_angry \n",
    "# can serve as an effective label for us.\n",
    "df = df.drop(['ferretID','disposition_nice'],axis=1)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the prepared data into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = '<<s3 bucket name>>'\n",
    "data_key = 'marketplace_logistic_regression'\n",
    "prepped_data_file = 'ferretData_prepped.csv'\n",
    "\n",
    "\n",
    "np.savetxt(prepped_data_file,df,delimiter=',')\n",
    "\n",
    "# Upload file to S3\n",
    "output_location = 's3://{}/{}'.format(bucket_name, 'output')\n",
    "data_location = output_location = 's3://{}/{}'.format(bucket_name, data_key)\n",
    "print (\"Training artifacts will be uploaded at: \" + output_location)\n",
    "print (\"And data_location will be a parameter for fit method (see training stage below).\")\n",
    "\n",
    "sess.upload_data(prepped_data_file, bucket=bucket_name, key_prefix=data_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify our hyperparameters, algorithm ARN and SageMaker Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only required hyperparameter for this algortihm is the number of classes.\n",
    "# Also, per the documentation of this algortihm the labels should be the last column.\n",
    "hyperparameters={\"nClasses\": 2}\n",
    "\n",
    "algo_subscription_arn = \"<<insert subscribed algorithm ARN here>>\"\n",
    "\n",
    "ferretDetector_LogRegress = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_subscription_arn,\n",
    "    base_job_name=\"ferretDetector-LogisticRegression\",\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get to Training Already!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferretDetector_LogRegress.fit({\"training\": data_location})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
